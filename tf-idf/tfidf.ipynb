{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Retrieval using TF-IDF Weighted Rank and TF-IDF Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-95cb1743e15f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnum2words\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnum2words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "from num2words import num2words\n",
    "\n",
    "import nltk\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import math\n",
    "\n",
    "# %load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"stories\"\n",
    "alpha = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking all folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [x[0] for x in os.walk(str(os.getcwd())+'/'+title+'/')]\n",
    "folders[0] = folders[0][:len(folders[0])-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/williamscott/Desktop/IR/Assignments/Assignment 2/stories',\n",
       " '/Users/williamscott/Desktop/IR/Assignments/Assignment 2/stories/FARNON',\n",
       " '/Users/williamscott/Desktop/IR/Assignments/Assignment 2/stories/SRE']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting the file names and titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452 452\n",
      "0 0\n",
      "15 15\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "\n",
    "c = False\n",
    "\n",
    "for i in folders:\n",
    "    file = open(i+\"/index.html\", 'r')\n",
    "    text = file.read().strip()\n",
    "    file.close()\n",
    "\n",
    "    file_name = re.findall('><A HREF=\"(.*)\">', text)\n",
    "    file_title = re.findall('<BR><TD> (.*)\\n', text)\n",
    "\n",
    "    if c == False:\n",
    "        file_name = file_name[2:]\n",
    "        c = True\n",
    "        \n",
    "    print(len(file_name), len(file_title))\n",
    "\n",
    "    for j in range(len(file_name)):\n",
    "        dataset.append((str(i) +\"/\"+ str(file_name[j]), file_title[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "467"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len (dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_doc(id):\n",
    "    print(dataset[id])\n",
    "    file = open(dataset[id][0], 'r', encoding='cp1250')\n",
    "    text = file.read().strip()\n",
    "    file.close()\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lower_case(data):\n",
    "    return np.char.lower(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(data):\n",
    "    stop_words = stopwords.words('english')\n",
    "    words = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in words:\n",
    "        if w not in stop_words and len(w) > 1:\n",
    "            new_text = new_text + \" \" + w\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(data):\n",
    "    symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    for i in range(len(symbols)):\n",
    "        data = np.char.replace(data, symbols[i], ' ')\n",
    "        data = np.char.replace(data, \"  \", \" \")\n",
    "    data = np.char.replace(data, ',', '')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_apostrophe(data):\n",
    "    return np.char.replace(data, \"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(data):\n",
    "    stemmer= PorterStemmer()\n",
    "    \n",
    "    tokens = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in tokens:\n",
    "        new_text = new_text + \" \" + stemmer.stem(w)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_numbers(data):\n",
    "    tokens = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            w = num2words(int(w))\n",
    "        except:\n",
    "            a = 0\n",
    "        new_text = new_text + \" \" + w\n",
    "    new_text = np.char.replace(new_text, \"-\", \" \")\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    data = convert_lower_case(data)\n",
    "    data = remove_punctuation(data) #remove comma seperately\n",
    "    data = remove_apostrophe(data)\n",
    "    data = remove_stop_words(data)\n",
    "    data = convert_numbers(data)\n",
    "    data = stemming(data)\n",
    "    data = remove_punctuation(data)\n",
    "    data = convert_numbers(data)\n",
    "    data = stemming(data) #needed again as we need to stem the words\n",
    "    data = remove_punctuation(data) #needed again as num2word is giving few hypens and commas fourty-one\n",
    "    data = remove_stop_words(data) #needed again as num2word is giving stop words 101 - one hundred and one\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "processed_text = []\n",
    "processed_title = []\n",
    "\n",
    "for i in dataset[:N]:\n",
    "    file = open(i[0], 'r', encoding=\"utf8\", errors='ignore')\n",
    "    text = file.read().strip()\n",
    "    file.close()\n",
    "\n",
    "    processed_text.append(word_tokenize(str(preprocess(text))))\n",
    "    processed_title.append(word_tokenize(str(preprocess(i[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating DF for all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DF = {}\n",
    "\n",
    "for i in range(N):\n",
    "    tokens = processed_text[i]\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            DF[w].add(i)\n",
    "        except:\n",
    "            DF[w] = {i}\n",
    "\n",
    "    tokens = processed_title[i]\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            DF[w].add(i)\n",
    "        except:\n",
    "            DF[w] = {i}\n",
    "for i in DF:\n",
    "    DF[i] = len(DF[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_vocab_size = len(DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32350"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "total_vocab = [x for x in DF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sharewar', 'trial', 'project', 'freewar', 'need', 'support', 'continu', 'one', 'hundr', 'west', 'fifti', 'three', 'north', 'jim', 'prentic', 'copyright', 'thousand', 'nine', 'nineti', 'brandon']\n"
     ]
    }
   ],
   "source": [
    "print(total_vocab[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_freq(word):\n",
    "    c = 0\n",
    "    try:\n",
    "        c = DF[word]\n",
    "    except:\n",
    "        pass\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating TF-IDF for body, we will consider this as the actual tf-idf as we will add the title weight to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "doc = 0\n",
    "\n",
    "tf_idf = {}\n",
    "\n",
    "for i in range(N):\n",
    "    \n",
    "    tokens = processed_text[i]\n",
    "    \n",
    "    counter = Counter(tokens + processed_title[i])\n",
    "    words_count = len(tokens + processed_title[i])\n",
    "    \n",
    "    for token in np.unique(tokens):\n",
    "        \n",
    "        tf = counter[token]/words_count\n",
    "        df = doc_freq(token)\n",
    "        idf = np.log((N+1)/(df+1))\n",
    "        \n",
    "        tf_idf[doc, token] = tf*idf\n",
    "\n",
    "    doc += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating TF-IDF for Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 0\n",
    "\n",
    "tf_idf_title = {}\n",
    "\n",
    "for i in range(N):\n",
    "    \n",
    "    tokens = processed_title[i]\n",
    "    counter = Counter(tokens + processed_text[i])\n",
    "    words_count = len(tokens + processed_text[i])\n",
    "\n",
    "    for token in np.unique(tokens):\n",
    "        \n",
    "        tf = counter[token]/words_count\n",
    "        df = doc_freq(token)\n",
    "        idf = np.log((N+1)/(df+1)) #numerator is added 1 to avoid negative values\n",
    "        \n",
    "        tf_idf_title[doc, token] = tf*idf\n",
    "\n",
    "    doc += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tf_idf_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002906893990853149"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf[(0,\"go\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002906893990853149"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_title[(0,\"go\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the TF-IDF according to weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tf_idf:\n",
    "    tf_idf[i] *= alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tf_idf_title:\n",
    "    tf_idf[i] = tf_idf_title[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344378"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Matching Score Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Score\n",
      "\n",
      "Query: Without the drive of Rebeccah's insistence, Kate lost her momentum. She stood next a slatted oak bench, canisters still clutched, surveying\n",
      "\n",
      "['without', 'drive', 'rebeccah', 'insist', 'kate', 'lost', 'momentum', 'stood', 'next', 'slat', 'oak', 'bench', 'canist', 'still', 'clutch', 'survey']\n",
      "\n",
      "[166, 200, 352, 433, 211, 350, 175, 187, 188, 294]\n"
     ]
    }
   ],
   "source": [
    "def matching_score(k, query):\n",
    "    preprocessed_query = preprocess(query)\n",
    "    tokens = word_tokenize(str(preprocessed_query))\n",
    "\n",
    "    print(\"Matching Score\")\n",
    "    print(\"\\nQuery:\", query)\n",
    "    print(\"\")\n",
    "    print(tokens)\n",
    "    \n",
    "    query_weights = {}\n",
    "\n",
    "    for key in tf_idf:\n",
    "        \n",
    "        if key[1] in tokens:\n",
    "            try:\n",
    "                query_weights[key[0]] += tf_idf[key]\n",
    "            except:\n",
    "                query_weights[key[0]] = tf_idf[key]\n",
    "    \n",
    "    query_weights = sorted(query_weights.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"\")\n",
    "    \n",
    "    l = []\n",
    "    \n",
    "    for i in query_weights[:10]:\n",
    "        l.append(i[0])\n",
    "    \n",
    "    print(l)\n",
    "    \n",
    "\n",
    "matching_score(10, \"Without the drive of Rebeccah's insistence, Kate lost her momentum. She stood next a slatted oak bench, canisters still clutched, surveying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_doc(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Cosine Similarity Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(a, b):\n",
    "    cos_sim = np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorising tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.zeros((N, total_vocab_size))\n",
    "for i in tf_idf:\n",
    "    try:\n",
    "        ind = total_vocab.index(i[1])\n",
    "        D[i[0]][ind] = tf_idf[i]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_vector(tokens):\n",
    "\n",
    "    Q = np.zeros((len(total_vocab)))\n",
    "    \n",
    "    counter = Counter(tokens)\n",
    "    words_count = len(tokens)\n",
    "\n",
    "    query_weights = {}\n",
    "    \n",
    "    for token in np.unique(tokens):\n",
    "        \n",
    "        tf = counter[token]/words_count\n",
    "        df = doc_freq(token)\n",
    "        idf = math.log((N+1)/(df+1))\n",
    "\n",
    "        try:\n",
    "            ind = total_vocab.index(token)\n",
    "            Q[ind] = tf*idf\n",
    "        except:\n",
    "            pass\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity\n",
      "\n",
      "Query: Without the drive of Rebeccah's insistence, Kate lost her momentum. She stood next a slatted oak bench, canisters still clutched, surveying\n",
      "\n",
      "['without', 'drive', 'rebeccah', 'insist', 'kate', 'lost', 'momentum', 'stood', 'next', 'slat', 'oak', 'bench', 'canist', 'still', 'clutch', 'survey']\n",
      "\n",
      "[200 166 433 175 169 402 211  87 151 369]\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(k, query):\n",
    "    print(\"Cosine Similarity\")\n",
    "    preprocessed_query = preprocess(query)\n",
    "    tokens = word_tokenize(str(preprocessed_query))\n",
    "    \n",
    "    print(\"\\nQuery:\", query)\n",
    "    print(\"\")\n",
    "    print(tokens)\n",
    "    \n",
    "    d_cosines = []\n",
    "    \n",
    "    query_vector = gen_vector(tokens)\n",
    "    \n",
    "    for d in D:\n",
    "        d_cosines.append(cosine_sim(query_vector, d))\n",
    "        \n",
    "    out = np.array(d_cosines).argsort()[-k:][::-1]\n",
    "    \n",
    "    print(\"\")\n",
    "    \n",
    "    print(out)\n",
    "\n",
    "#     for i in out:\n",
    "#         print(i, dataset[i][0])\n",
    "\n",
    "Q = cosine_similarity(10, \"Without the drive of Rebeccah's insistence, Kate lost her momentum. She stood next a slatted oak bench, canisters still clutched, surveying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/Users/williamscott/Desktop/IR/Assignments/Assignment 2/stories/ghost', 'Time for Flowers, by Gay Bost')\n",
      "TIME FOR FLOWERS\n",
      "  by Gay Bost\n",
      "\n",
      "They'd put flowers up. She hadn't noticed. Time wouldn't hold still.\n",
      "She remembered, quite clearly, that time had been a simple thing; one\n",
      "moment following the previous one, seconds strung out neatly like her\n",
      "mother's pearls laid out on the dark mahogany vanity each Sunday\n",
      "morning. But there had been a catch . . . \n",
      "\n",
      "Hung around Mother's neck the catch clicked and the tidy little line \n",
      "of seconds became a never ending circle with only the catch in the \n",
      "middle. For some reason the thought of pearls gathered from the sea, \n",
      "naturally nested within the confines of oyster shells, scattered \n",
      "haphazardly about the ocean floor disturbed her.\n",
      "\n",
      "Now they'd put up the flowers in the same careless groupings. This,\n",
      "too, disturbed her. Bright yellow trumpets, their collars spread to\n",
      "catch the sun, dotted the front yard in clusters of two or three, five\n",
      "or six. Bunches laid carelessly and forgotten. In a moment she'd\n",
      "come away from the window and have a word with the gardener. He\n",
      "listened so well and explained to others so reasonably why this should\n",
      "be so instead of the way they wanted it done, how that would look\n",
      "better or cut the wind more effectively.\n",
      "\n",
      "And then she recalled his stiff body stretched out in the little bed\n",
      "over the garages. Another pearl had come loose from the strand,\n",
      "seeming to want to search out its old home in a far away oyster bed.\n",
      "She would have those pearls laid out neatly, one following the one\n",
      "before and so on and so on. She would have those damned yellow\n",
      "flowers marching smartly along the walk. She'd have it if she\n",
      "had to go out there and replant each and every one of them.\n",
      "\n",
      "She flew down the hallway and sailed over the steps leading the\n",
      "back way to the kitchen, much as she had done as a child. Where then\n",
      "she had skipped in joy she now catapulted her form in anger.\n",
      "\n",
      "\"And there you are!\" she said, as she encountered the woman she had \n",
      "come to know as Kate. All of five foot tall in her stocking feet and \n",
      "surely every bit of two hundred pounds, her pudgy fists more often \n",
      "than not braced on the sudden outburst of her hips. So she stood, \n",
      "having turned from the sink. Suds and water darkened the fabric of her \n",
      "dress. Her face was pleasant; round, rosy cheeked, with eyes the color \n",
      "of mint in the summer sunset. \"And *where have you been these three days*?\"\n",
      "\n",
      "\"I want the flowers straightened out,\" Rebeccah said. \"I want the\n",
      "flowers placed in the proper alignments.\"\n",
      "\n",
      "Kate tilted her head, narrowed her eyes and frowned. \"Ah, you're in a\n",
      "huff again. What can it be this time?\"\n",
      "\n",
      "\"I want the flours straightened out,\" Rebeccah yelled, coming up to\n",
      "the woman's face.\n",
      "\n",
      "Kate went directly to the cupboard, strained upon her tiny toes to\n",
      "reach the second shelf, and pulled the flour canister out. She set it\n",
      "on the counter. She repeated the process, bringing out a smaller\n",
      "canister. Rebecca knew this one to be the unbleached flour Kate used\n",
      "for one particular recipe.\n",
      "\n",
      "\"No,no, no!\"  Rebeccah hissed. \"Flowers!  Not flours!\"  She propped\n",
      "herself against the edge of the kitchen table and crossed her arms\n",
      "over her chest, waiting for the woman to get it right.\n",
      "\n",
      "Kate stood looking dumbly at the canisters. \"Now, what was I going to\n",
      "do with these?\"  she asked herself. She drummed her fingers on the\n",
      "counter top before bringing one hand to her lips, where the pointer\n",
      "finger tapped on her upper lip.\n",
      "\n",
      "\"The Flowers!  Outside!\"  Rebecca screamed, highly agitated.\n",
      "\n",
      "Kate gathered the two canisters and moved toward the back door, one\n",
      "held against her ample form by each arm.\n",
      "\n",
      "Exasperated, Rebeccah followed her out, watching to see what she would do.\n",
      "\n",
      "Without the drive of Rebeccah's insistence, Kate lost her momentum.\n",
      "She stood next a slatted oak bench, canisters still clutched, surveying \n",
      "the sunlit yard and gardens beyond. Harold had done a passable job \n",
      "trimming the hedges, but Kate missed the gardener's touch. She resolved \n",
      "to contact the nursery and find another. Flaux, bright purples, pinks \n",
      "and radiant white encircled the herb garden, a brilliant contrast to \n",
      "the varied greens within. She set the canisters down on the bench and \n",
      "moved toward the cheerful scene.\n",
      "\n",
      "Rebeccah, discouraged, sat primly on the edge of the bench, dusting a\n",
      "wisp of hair away from her temple. New mint, dew draped, veiled a\n",
      "border of stocky wooden poles to trail onto the walk, had been crushed, \n",
      "probably by the man of the house on his way off to work. The scent \n",
      "filled her nostrils. She found herself a child, again, tasting her \n",
      "first tea with mint -- fresh cut from the gardens. _\"How long has it\n",
      "been?\"_  she wondered. Kate had gone down on her knees over the flaux,\n",
      "bending to weed through the thyme.\n",
      "\n",
      "\"I don't know why I have to put up with idiots,\" Rebeccah complained.\n",
      "\"It all so worthless, so futile.\"  With a great sigh she rose from the\n",
      "bench and made her way back into the house. The bright kitchen seemed\n",
      "a waste of life, all a travesty to cover the desolation of her\n",
      "unnaturally extended existence. \n",
      "\n",
      "She faced the stairs with exhaustion, deciding, instead, to forego the \n",
      "trip up. She sat on the bottom step, delicate chin propped on tightly \n",
      "curled fists, gazing dully at the open pantry door, seeing into the past \n",
      "-- again. Where, in this world the shelves were haphazardly stacked with \n",
      "cans of peaches and corn, she saw row after row of glass jars. Beets!  \n",
      "Ugh!  Her grandmother's pickled beets, always pretty to view, left a \n",
      "phantom bitterness within her mouth.\n",
      "\n",
      "On the lawn Kate sat back on her heels, suddenly lost in sorrow and\n",
      "self-pity. Tears streamed down her cheeks to drop onto the fabric of\n",
      "her dress. She thought of Harold, busily showing homes as lovely as\n",
      "their own to strangers while she ruined her nails weeding this pitiful\n",
      "excuse for a garden. She shoved her pudgy fists into her burning eyes\n",
      "and wept aloud for the waste of her life. She sniffed back her running \n",
      "nose . . . sniffed again. She snuffled like a dog scenting something \n",
      "unusual, nose in the air. \"Beets?\"  she asked aloud. \"Beets?\"  Her \n",
      "hands dropped to her thighs, pushing to rise. _\"Of course,\"_ she thought \n",
      "to herself, _\"this *lovely* house is haunted by a very emotional woman.\"_  \n",
      "Her knees ached. She turned toward the house and noticed the flour \n",
      "canisters on the bench. \"And whatever she wants *this* time is not \n",
      "getting through this thick skull of mine!\"\n",
      "\n",
      "Kate knuckle-rapped herself above her right temple. \"Rebeccah!\"  she\n",
      "called. \"Quit moping!  You'll ruin another day for me and I still\n",
      "have to deal with that horrible Avon woman this morning.\"\n",
      "\n",
      "\"I want my flowers properly aligned!\" Rebeccah screamed from the stairs.\n",
      "\n",
      "As Kate passed the bench she paused to move the flour canisters so\n",
      "that the labels faced in the same direction, each perfectly centered\n",
      "over three of the wood slats. With a self-satisfied air she re-entered \n",
      "her own kitchen. \"Now,\" she began, addressing the refrigerator, \"what \n",
      "we need is improved communication.\"\n",
      "\n",
      "\"Fool,\" hissed Rebeccah, \"you're talking to the refrigerator again.\"\n",
      "\n",
      "\"You don't want an empath. You want a telepath,\" Kate said, turning\n",
      "to stare at Rebeccah with surprising accuracy.\n",
      "\n",
      "The two women blinked at each other and broke into laughter.\n",
      "\n",
      "\"I want my flowers straightened out!\"  Rebeccah commented softly when\n",
      "the mirth had passed.\n",
      "\n",
      "                              * * *\n",
      "\n",
      "\"There!\"  Kate replaced the telephone hand piece and pocketed the\n",
      "scrap of paper she'd written the new gardener's name upon. \"Mr.\n",
      "Hi-a-cow-wah,\" she practiced aloud. \"Very good.\"  The door chime rang\n",
      "throughout the house, echoing off the tiled kitchen walls.\n",
      "\n",
      "\"Oh, no!\"  wailed Rebeccah. \"Not Japanese!  They have such spiritual\n",
      "ideas on gardening -- I'll never get through to him!\"\n",
      "\n",
      "\"Oh, dear!\"  Kate bemoaned, certain the Avon woman had come to call.\n",
      "She brushed her hands over her skirt, straightened her broad shoulders\n",
      "and pushed through to the dining room, determined not to buy a single\n",
      "thing today.\n",
      "\n",
      "\"Good morning, Mrs. Blanchard!\"  beamed the woman in the pale rose\n",
      "colored ensemble. Purse clutched in one hand, sample case in the other, \n",
      "she reminded Kate of the Lady Justice, scales perfectly balanced. But \n",
      "this lady had no blindfold. (All the better to see you with, my dear. \n",
      "And Oh, wouldn't this color just bring on the blush in your cheeks for \n",
      "$11.00 a tube?)  \"Isn't it just a glorious day?\" the woman pronouned, \n",
      "boldly stepping over the threshold on past assumptions.\n",
      "\n",
      "_\"That's it!\"_ Kate thought to herself. She'd let the woman in once,\n",
      "bought gifts soaps and lipstick in the spirit of cooperation, and\n",
      "never been free of past assumptions since. \"Glorious!\" Kate echoed,\n",
      "moving aside before she was trod upon. Rebeccah hovered at the dining\n",
      "room doors. Kate felt her there.\n",
      "\n",
      "\"Oh, and you've brought the day in with you!\" exclaimed the woman,\n",
      "noting cut flowers on mantel and coffee table. \"How healthful!\"\n",
      "\n",
      "\"Healthful?\" Kate inquired.\n",
      "\n",
      "\"Oh, yes. Studies have shown that people who surround themselves with\n",
      "live plants and fresh flowers indoors live longer, feel better, and\n",
      "enjoy life more fully.\"\n",
      "\n",
      "\"Coffee?\"  Kate offered as the woman sat on the edge of the sofa. It\n",
      "was the one torment she allowed herself to use on the woman, knowing\n",
      "full well this door to door saleswoman would shun other people's\n",
      "bathrooms.\n",
      "\n",
      "\"No thank you,\" she answered, a slight grimace flashing across her\n",
      "face as she scooted forward and opened her case.\n",
      "\n",
      "\"You're so rude!\" Rebeccah crowed, having come closer. \"She's got a\n",
      "bladder full now.\"\n",
      "\n",
      "Kate smiled, holding back a giggle. She was certain she'd scored\n",
      "without knowing why. The woman drew forth brightly colored sheets of\n",
      "paper and placed them neatly before Kate on the glass topped table.\n",
      "_\"A promotional,\"_ Kate moaned within her mind. At the bottom of each\n",
      "was stamped, in flowing script, \"Eleanor Thomsason.\"  Address and two\n",
      "phone numbers followed in block lettering.\n",
      "\n",
      "\"I don't really need anything today, Eleanor,\" Kate began.\n",
      "\n",
      "\"Of course you don't, dear. You're more than lovely in your house\n",
      "frock and clean scrubbed face. But you must see the new complexion\n",
      "care line we're offering. Designed especially for the woman over 30\n",
      "and her special needs,\" Eleanor pulled full sized display item from\n",
      "the depths of her bottomless case and set them neatly in a row,\n",
      "labels facing the prospective buyer. \"As you can see here,\" she said\n",
      "crisply, long manicured finger nail tapping each item gently as she\n",
      "spoke, \"We have a scrub, toner, tightener, moisturizer and light\n",
      "foundation. The foundation comes in 6 basic colors. Just to smooth\n",
      "over those tiny blotches we all seem to have after 30.\"\n",
      "\n",
      "Kate sat forward in her occasional chair, considering the possibility\n",
      "that she might, indeed, need a little more complexion care. She\n",
      "touched the toner, tilting it slightly to the light. While she was\n",
      "otherwise engaged Eleanor brought forth tubes, bottles and jars of the\n",
      "same line. She busied herself arranging them in a straight line to\n",
      "the left and just behind the first row.\n",
      "\n",
      "\"And here we have the corresponding blush, highlighters, lipsticks \n",
      "and shadows. Now this line is made with completely natural base\n",
      "substances,\" Eleanor pointed out.\n",
      "\n",
      "\"Chemicals,\" Rebeccah commented, coming closer still, intently\n",
      "interested in the ordered presentation.\n",
      "\n",
      "Kate let go the toner and reached for the blush. Eleanor straightened\n",
      "the toner, turning the label toward the prospective buyer. Rebeccah\n",
      "came around the coffee table and sat on the sofa with Eleanor, her\n",
      "arms primly at her sides, hands clasped in her lap. Rebeccah leaned\n",
      "forward in the same manner as did Eleanor.\n",
      "\n",
      "The genial rise and fall of the woman's voice slipped into the background \n",
      "of sounds passing by on the peaceful street outside. Kate blinked once, \n",
      "the blush still clasped within her fingers, watching Eleanor's lips move. \n",
      "She could almost hear Rebeccah.\n",
      "\n",
      "Rebeccah's attention was focused entirely on Eleanor the Avon lady.\n",
      "\"The flowers have been scattered willy-nilly along the walk,\"\n",
      "Rebeccah said conversationally, her lips mere inches from Eleanor's\n",
      "ear. \"They look so untidy.\"  Eleanor looked, suddenly, as if she'd\n",
      "forgotten something. Kate remembered the flour canisters on the\n",
      "bench. \"What we need is someone with some organizational ability,\"\n",
      "Rebeccah continued. \n",
      "\n",
      "Eleanor drew forth her order book. \"Flowers are like life's little \n",
      "markers,\" Rebeccah whispered. Eleanor reached into her case for a \n",
      "marker. \"Yellow markers, as it were, for the days of our lives.\"  \n",
      "Eleanor replaced the fine tipped black marker and retrieved a broad \n",
      "stroke yellow highlighter. Kate seemed to hear McDonald Carey speaking \n",
      "about sand. \"The flowers along the walk NEED straightening.\"\n",
      "\n",
      "\"Will you excuse me, just one moment?\" Kate asked. She knew exactly\n",
      "where to find that hourglass. She rose from her chair\n",
      "\n",
      "\"Certainly, dear,\" Eleanor answered, her mind seemingly elsewhere\n",
      "while her hands compulsively aligned the display items.\n",
      "\n",
      "\"*YOU* could be the only one for the job!\"  Rebeccah spoke\n",
      "authoritatively, her body turned toward Eleanor. \"The flowers need\n",
      "alignment!\"\n",
      "\n",
      "Kate felt an oppressive headache coming on. Two of them in one\n",
      "morning was more than anyone should be expected to bear. As she\n",
      "passed through the kitchen door her spirits seemed to rise suddenly.\n",
      "Sunshine slanted into the room to highlight every gleaming surface,\n",
      "glinting sweetly on glassware and chrome. She inhaled fully, filling\n",
      "her lungs with the aroma of fresh brewed coffee. The hourglass\n",
      "spilling out the days of her life seemed important only in the\n",
      "abstract. All was right today. She thought of the flowers by the\n",
      "walk, then. For some reason she  wanted to see them from the top\n",
      "floor.\n",
      "\n",
      "She poured herself a cup of coffee, carried it up the back stairs to\n",
      "the second floor landing and peered from the window into the side\n",
      "yard. She thought, idly, of the new gardener, and what creative\n",
      "expression he might come up with for that spot there, which had never\n",
      "been cultivated. Onward, to the front of the house, and into the\n",
      "quiet room beneath the pitch of the front eaves. \n",
      "\n",
      "She sat on the window ledge and balanced her cup on the sill, the \n",
      "threatened headache a memory, only, of Saturday afternoons with her \n",
      "mother. Somewhere behind her temples her mother's voice droned on and \n",
      "on; something about book spines and the edge of the shelf. Sometimes \n",
      "one had to learn to ignore the librarian in order to read the books.\n",
      "\n",
      "Her eyes drifted to the front walk. Far below, as if in another\n",
      "world, Eleanor the Avon lady knelt in the grass next to the walk.\n",
      "A tall shadow stood near, softly, insistently coaxing, as Eleanor\n",
      "carefully spaded deep into the earth and removed a daffodil. She\n",
      "placed it gently into a prepared hole, tamped the earth around it and\n",
      "proceeded to dig another hole, exactly six inches from the last, in a\n",
      "perfectly straight line parallel to the walk.\n",
      "\n",
      "\"Oh, for crying out loud!\"  Kate exclaimed, watching closely. \"Those\n",
      "flowers!\"  She'd have to remember to collect the flour canisters\n",
      "before Harold came home. \"Goodness, Rebeccah,\" she continued, with\n",
      "some exasperation, \"why on earth didn't you say `Daffodils'?\"\n",
      "\n",
      "                              # # #\n",
      "\n",
      "Copyright 1994 Gay Bost\n",
      "--------------------------------------------------------------------------\n",
      " Gay is a Clinical Lab Tech with experience in Veterinary medicine. \n",
      "Originally from NORTHERN California, she has resided in Southeast Missouri \n",
      "with her husband and an aggressive 6 year old boy, since 1974. She \n",
      "installed her first modem in the summer of 1992 and has been exploring new \n",
      "worlds since. Her first and only publication, a short horror story, came \n",
      "when she was 17 years old. The success was so overwhelming she called an \n",
      "end to her writing days and went in search of herself. She's still looking. \n",
      "You will find Gay's work in the best Electronic Magazines.\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "print_doc(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
